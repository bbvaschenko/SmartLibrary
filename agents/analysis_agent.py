import json
import logging
from typing import List, Dict, Any
from gigachat_client import GigaChatClient

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
class AnalysisAgent:
    """–ê–≥–µ–Ω—Ç –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""

    def __init__(self, verify_ssl: bool = False):
        self.client = GigaChatClient(verify_ssl=verify_ssl)
        logger.info("AnalysisAgent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        self.analysis_prompt = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –≥–ª—É–±–æ–∫–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º.

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ê–ù–ê–õ–ò–ó–£:

1. –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–¨ –¢–ï–ú–ï:
   - –û—Ü–µ–Ω–∏—Ç—å –Ω–∞—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ (0-10 –±–∞–ª–ª–æ–≤)
   - –í—ã–¥–µ–ª–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—â–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
   - –û—Ç–º–µ—Ç–∏—Ç—å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Ç–µ–º—ã, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å

2. –£–†–û–í–ï–ù–¨ –°–õ–û–ñ–ù–û–°–¢–ò:
   - –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (–Ω–∞—á–∞–ª—å–Ω—ã–π, —Å—Ä–µ–¥–Ω–∏–π, –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π, —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π)
   - –£–∫–∞–∑–∞—Ç—å —Ñ–∞–∫—Ç–æ—Ä—ã, –≤–ª–∏—è—é—â–∏–µ –Ω–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å
   - –û—Ü–µ–Ω–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π

3. –°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –¶–ï–õ–ï–í–û–ô –ê–£–î–ò–¢–û–†–ò–ò:
   - –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ü–µ–ª–µ–≤—É—é –∞—É–¥–∏—Ç–æ—Ä–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞
   - –û—Ü–µ–Ω–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è
   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∏–ª—è –∏ —Ç–æ–Ω–∞ –∞—É–¥–∏—Ç–æ—Ä–∏–∏

4. –ö–õ–Æ–ß–ï–í–´–ï –ü–û–ù–Ø–¢–ò–Ø:
   - –í—ã–¥–µ–ª–∏—Ç—å 5-10 –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π –∏ —Ç–µ—Ä–º–∏–Ω–æ–≤
   - –î–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø–æ–Ω—è—Ç–∏—è
   - –û—Ü–µ–Ω–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞

5. –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø:
   - –í—ã—è–≤–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
   - –û—Ç–º–µ—Ç–∏—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
   - –£–∫–∞–∑–∞—Ç—å –Ω–∞ –ø—Ä–æ–±–µ–ª—ã –≤ –æ—Å–≤–µ—â–µ–Ω–∏–∏ —Ç–µ–º—ã

6. –ö–†–ê–¢–ö–û–ï –†–ï–ó–Æ–ú–ï:
   - –°–æ–∑–¥–∞—Ç—å –ª–∞–∫–æ–Ω–∏—á–Ω–æ–µ —Ä–µ–∑—é–º–µ (3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)
   - –í—ã–¥–µ–ª–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é –º—ã—Å–ª—å
   - –û—Ç–º–µ—Ç–∏—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ü–µ–Ω–Ω–æ—Å—Ç—å

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π:
{
  "relevance_analysis": {
    "score": 8,
    "explanation": "–¢–µ–∫—Å—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏—è",
    "key_points": ["–ø—É–Ω–∫—Ç1", "–ø—É–Ω–∫—Ç2"],
    "deviations": ["–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ1", "–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ2"]
  },
  "complexity_analysis": {
    "level": "—Å—Ä–µ–¥–Ω–∏–π",
    "factors": ["—Ñ–∞–∫—Ç–æ—Ä1", "—Ñ–∞–∫—Ç–æ—Ä2"],
    "prerequisites": ["–∑–Ω–∞–Ω–∏–µ1", "–∑–Ω–∞–Ω–∏–µ2"]
  },
  "audience_analysis": {
    "target_audience": "–∞—É–¥–∏—Ç–æ—Ä–∏—è",
    "accessibility": "–æ—Ü–µ–Ω–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏",
    "style_match": "—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∏–ª—è"
  },
  "key_concepts": [
    {"concept": "–ø–æ–Ω—è—Ç–∏–µ1", "explanation": "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ", "importance": "–≤—ã—Å–æ–∫–∞—è"},
    {"concept": "–ø–æ–Ω—è—Ç–∏–µ2", "explanation": "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ", "importance": "—Å—Ä–µ–¥–Ω—è—è"}
  ],
  "limitations": [
    {"limitation": "–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ1", "impact": "–≤–ª–∏—è–Ω–∏–µ", "suggestion": "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è"},
    {"limitation": "–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ2", "impact": "–≤–ª–∏—è–Ω–∏–µ", "suggestion": "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è"}
  ],
  "summary": "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"
}"""

    def analyze_single_content(self, content: str, topic: str = None, target_audience: str = None) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ –≤—Å–µ–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º"""

        print("üîç –ù–∞—á–∏–Ω–∞—é –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        analysis_prompt = f"""
–ö–û–ù–¢–ï–ù–¢ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{content}

–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ –ê–ù–ê–õ–ò–ó–ê:
- –¢–µ–º–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {topic if topic else "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"}
- –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: {target_audience if target_audience else "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"}

–ü—Ä–æ–≤–µ–¥–∏ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –≤—Å–µ–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º.
"""

        try:
            result = self.client.chat_json(
                prompt=analysis_prompt,
                system_prompt=self.analysis_prompt,
                temperature=0.2,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
                max_tokens=3000
            )

            print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            return result

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
            return {"error": str(e)}

    def process(self, query: str = None, content: str = None, contents: List[Dict] = None,
                topic: str = None, target_audience: str = None, context: Dict = None) -> Dict[str, Any]:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞.
        –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –≤—ã–∑—ã–≤–∞–µ—Ç –ª–∏–±–æ –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –ª–∏–±–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö.
        """
        logger.info(f"AnalysisAgent: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ - {query[:100] if query else '–±–µ–∑ –∑–∞–ø—Ä–æ—Å–∞'}")

        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —á—Ç–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
            if content is not None:
                logger.info("–í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
                return self.analyze_single_content(content, topic, target_audience)

            elif contents is not None and len(contents) > 0:
                logger.info(f"–í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ {len(contents)} –∫–æ–Ω—Ç–µ–Ω—Ç–æ–≤")
                return self.analyze_multiple_contents(contents, topic)

            elif context:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                if 'content' in context:
                    logger.info("–ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ")
                    return self.analyze_single_content(
                        content=context.get('content'),
                        topic=context.get('topic', topic),
                        target_audience=context.get('target_audience', target_audience)
                    )
                elif 'contents' in context:
                    logger.info(f"–ù–∞–π–¥–µ–Ω—ã {len(context.get('contents', []))} –∫–æ–Ω—Ç–µ–Ω—Ç–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ")
                    return self.analyze_multiple_contents(
                        context.get('contents', []),
                        context.get('topic', topic)
                    )
                else:
                    return {
                        "error": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ",
                        "context_keys": list(context.keys())
                    }
            else:
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                return {
                    "error": "–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç. –£–∫–∞–∂–∏—Ç–µ content –∏–ª–∏ contents –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö.",
                    "suggestion": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ analyze_single_content() –∏–ª–∏ analyze_multiple_contents() –Ω–∞–ø—Ä—è–º—É—é"
                }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ AnalysisAgent.process: {e}")
            return {"error": str(e)}

    def analyze_multiple_contents(self, contents: List[Dict[str, str]], topic: str = None) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–Ω—Ç–æ–≤"""

        print(f"üîç –ù–∞—á–∏–Ω–∞—é —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ {len(contents)} –∫–æ–Ω—Ç–µ–Ω—Ç–æ–≤...")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç–¥–µ–ª—å–Ω–æ
        individual_analyses = []
        for i, content_item in enumerate(contents):
            print(f"üìÑ –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ {i + 1}/{len(contents)}...")

            content_id = content_item.get("id", f"content_{i + 1}")
            content_text = content_item.get("text", "")
            title = content_item.get("title", f"–ö–æ–Ω—Ç–µ–Ω—Ç {i + 1}")

            analysis = self.analyze_single_content(content_text, topic)

            individual_analyses.append({
                "id": content_id,
                "title": title,
                "analysis": analysis
            })

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤—Å–µ –∫–æ–Ω—Ç–µ–Ω—Ç—ã
        comparison = self._compare_contents(individual_analyses, topic)

        return {
            "individual_analyses": individual_analyses,
            "comparative_analysis": comparison,
            "recommendations": self._generate_recommendations(individual_analyses)
        }

    def _compare_contents(self, analyses: List[Dict], topic: str = None) -> Dict[str, Any]:
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–Ω—Ç–æ–≤"""

        print("‚öñÔ∏è  –ü—Ä–æ–≤–æ–∂—É —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑...")

        comparison_prompt = f"""
–ê–ù–ê–õ–ò–ó–´ –ö–û–ù–¢–ï–ù–¢–û–í:
{json.dumps(analyses, ensure_ascii=False, indent=2)}

–¢–ï–ú–ê –î–õ–Ø –°–†–ê–í–ù–ï–ù–ò–Ø: {topic if topic else "–æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞"}

–°—Ä–∞–≤–Ω–∏ –∫–æ–Ω—Ç–µ–Ω—Ç—ã –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º:
1. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–µ–º–µ
2. –£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
3. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏
4. –ö–∞—á–µ—Å—Ç–≤–æ –∏–∑–ª–æ–∂–µ–Ω–∏—è
5. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å

–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
  "comparison_matrix": [
    {{
      "content_id": "id1",
      "relevance_rank": 1,
      "complexity_rank": 2,
      "overall_score": 8.5,
      "best_for": ["—Å–∏—Ç—É–∞—Ü–∏—è1", "—Å–∏—Ç—É–∞—Ü–∏—è2"],
      "worst_for": ["—Å–∏—Ç—É–∞—Ü–∏—è3", "—Å–∏—Ç—É–∞—Ü–∏—è4"]
    }}
  ],
  "best_overall": "id_–ª—É—á—à–µ–≥–æ_–∫–æ–Ω—Ç–µ–Ω—Ç–∞",
  "best_for_beginners": "id_–¥–ª—è_–Ω–∞—á–∏–Ω–∞—é—â–∏—Ö",
  "best_for_experts": "id_–¥–ª—è_—ç–∫—Å–ø–µ—Ä—Ç–æ–≤",
  "summary": "–°–≤–æ–¥–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"
}}
"""

        try:
            result = self.client.chat_json(
                prompt=comparison_prompt,
                system_prompt="–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞. –°—Ä–∞–≤–Ω–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–Ω—Ç–æ–≤ –∏ –≤—ã–¥–µ–ª–∏ –∏—Ö —Å–∏–ª—å–Ω—ã–µ –∏ —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã.",
                temperature=0.3,
                max_tokens=2500
            )
            return result
        except Exception as e:
            return {"error": f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {str(e)}"}

    def _generate_recommendations(self, analyses: List[Dict]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""

        recommendation_prompt = f"""
–ê–ù–ê–õ–ò–ó–´ –ö–û–ù–¢–ï–ù–¢–û–í:
{json.dumps(analyses, ensure_ascii=False, indent=2)}

–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
1. –ö–∞–∫–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ü–µ–ª–µ–π
2. –í –∫–∞–∫–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑—É—á–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç—ã
3. –ö–∞–∫–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –º–æ–≥—É—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è

–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
  "usage_recommendations": [
    {{
      "purpose": "—Ü–µ–ª—å",
      "recommended_content": "id_–∫–æ–Ω—Ç–µ–Ω—Ç–∞",
      "reason": "–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ",
      "study_time": "–æ—Ü–µ–Ω–æ—á–Ω–æ–µ –≤—Ä–µ–º—è"
    }}
  ],
  "learning_path": [
    {{
      "step": 1,
      "content_id": "id1",
      "action": "–¥–µ–π—Å—Ç–≤–∏–µ",
      "expected_outcome": "—Ä–µ–∑—É–ª—å—Ç–∞—Ç"
    }}
  ],
  "supplementary_materials": [
    {{
      "type": "—Ç–∏–ø –º–∞—Ç–µ—Ä–∏–∞–ª–∞",
      "description": "–æ–ø–∏—Å–∞–Ω–∏–µ",
      "purpose": "–¥–ª—è —á–µ–≥–æ –Ω—É–∂–µ–Ω"
    }}
  ]
}}
"""

        try:
            result = self.client.chat_json(
                prompt=recommendation_prompt,
                system_prompt="–¢—ã - –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç. –°–æ–∑–¥–∞–π –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–æ–≤.",
                temperature=0.4,
                max_tokens=2000
            )
            return result
        except Exception as e:
            return {"error": f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {str(e)}"}

    def analyze_file(self, file_path: str, topic: str = None, target_audience: str = None) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ –≤ –∞–Ω–∞–ª–∏–∑
            file_info = {
                "file_name": file_path.split('/')[-1],
                "file_size_chars": len(content),
                "file_size_words": len(content.split())
            }

            analysis = self.analyze_single_content(content, topic, target_audience)
            analysis["file_info"] = file_info

            return analysis

        except FileNotFoundError:
            return {"error": f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}"}
        except Exception as e:
            return {"error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}"}

    def save_analysis_report(self, analysis: Dict[str, Any], output_file: str = "analysis_report.json"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –æ–± –∞–Ω–∞–ª–∏–∑–µ –≤ JSON —Ñ–∞–π–ª"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2, default=str)
            print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {output_file}")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            return False